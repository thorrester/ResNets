{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Dependencies\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import utils\n",
    "from keras import np_\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "#Confirm keras is using GPU\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "#Manually set GPU config\n",
    "config = tf.ConfigProto(device_count = {'GPU': 1, 'CPU': 8})\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n",
      "X_test shape: (10000, 28, 28, 1)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "((X_train_raw, y_train_raw), (X_test_raw, y_test_raw)) = fashion_mnist.load_data()\n",
    "\n",
    "# Reshape data\n",
    "X_train_raw = np.array(X_train_raw).reshape(-1,28,28,1)\n",
    "X_test_raw = np.array(X_test_raw).reshape(-1,28,28,1)\n",
    "\n",
    "# Normalize X data\n",
    "X_train = X_train_raw/255\n",
    "X_test = X_test_raw/255\n",
    "\n",
    "# Reshape y\n",
    "y_train = utils.to_categorical(y_train_raw, num_classes=10)\n",
    "y_test = utils.to_categorical(y_test_raw, num_classes=10)\n",
    "\n",
    "# Shape of data\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('y_train shape: ' + str(y_train.shape))\n",
    "print('X_test shape: ' + str(X_test.shape))\n",
    "print('y_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the ResNet\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape=(28, 28, 1), classes=10):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = ResNet50(input_shape = (28, 28, 1), classes = 10)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 1)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 14, 14, 64)   3200        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 14, 14, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 64)     0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 6, 6, 64)     4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 6, 6, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 6, 6, 64)     36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 6, 6, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 6, 6, 256)    16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 6, 6, 256)    16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 6, 6, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 6, 6, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 6, 6, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 256)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 6, 6, 64)     16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 6, 6, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 6, 6, 64)     36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 6, 6, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 6, 6, 256)    16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 6, 6, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 6, 6, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 256)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 6, 6, 64)     16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 6, 6, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 6, 6, 64)     36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 6, 6, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 6, 6, 256)    16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 6, 6, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 6, 6, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 6, 6, 256)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 3, 3, 128)    32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 3, 3, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 3, 3, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 3, 3, 512)    131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 3, 3, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 3, 3, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 3, 3, 512)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 3, 3, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 3, 3, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 3, 3, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 3, 3, 512)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 3, 3, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 3, 3, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 3, 3, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 3, 3, 512)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 3, 3, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 3, 3, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 3, 3, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 512)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 2, 2, 1024)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 1024)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 1024)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1, 1, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 1, 1, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1, 1, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 2048)   0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           20490       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,601,930\n",
      "Trainable params: 23,548,810\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 176s 3ms/step - loss: 0.6179 - acc: 0.7944 - val_loss: 0.4238 - val_acc: 0.8475\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.3476 - acc: 0.8741 - val_loss: 0.3705 - val_acc: 0.8623\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.3023 - acc: 0.8894 - val_loss: 0.3482 - val_acc: 0.8763\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.2668 - acc: 0.9027 - val_loss: 0.3332 - val_acc: 0.8797\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.2463 - acc: 0.9089 - val_loss: 0.3170 - val_acc: 0.8832\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.2325 - acc: 0.9140 - val_loss: 0.3248 - val_acc: 0.8883\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.2181 - acc: 0.9196 - val_loss: 0.3355 - val_acc: 0.8793\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.2053 - acc: 0.9253 - val_loss: 0.3085 - val_acc: 0.8950\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1950 - acc: 0.9289 - val_loss: 0.3103 - val_acc: 0.8980\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.1868 - acc: 0.9304 - val_loss: 0.3199 - val_acc: 0.8910\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.1774 - acc: 0.9336 - val_loss: 0.3077 - val_acc: 0.8977\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.1711 - acc: 0.9371 - val_loss: 0.2984 - val_acc: 0.8993\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.1634 - acc: 0.9394 - val_loss: 0.3149 - val_acc: 0.9020\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1564 - acc: 0.9423 - val_loss: 0.3281 - val_acc: 0.8927\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.1497 - acc: 0.9440 - val_loss: 0.3599 - val_acc: 0.8740\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.4734 - acc: 0.8566 - val_loss: 0.3189 - val_acc: 0.8830\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.2646 - acc: 0.9032 - val_loss: 0.2728 - val_acc: 0.9007\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.2163 - acc: 0.9190 - val_loss: 0.2687 - val_acc: 0.9020\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1890 - acc: 0.9300 - val_loss: 0.3119 - val_acc: 0.8953\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1723 - acc: 0.9351 - val_loss: 0.2780 - val_acc: 0.9038\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1548 - acc: 0.9406 - val_loss: 0.2966 - val_acc: 0.9007\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1431 - acc: 0.9459 - val_loss: 0.3735 - val_acc: 0.8840\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1320 - acc: 0.9500 - val_loss: 0.3251 - val_acc: 0.9043\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1227 - acc: 0.9539 - val_loss: 0.2757 - val_acc: 0.9070\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1176 - acc: 0.9553 - val_loss: 0.3170 - val_acc: 0.8975\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1100 - acc: 0.9580 - val_loss: 0.3095 - val_acc: 0.9018\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0996 - acc: 0.9625 - val_loss: 0.3219 - val_acc: 0.9052\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0959 - acc: 0.9638 - val_loss: 0.3747 - val_acc: 0.8982\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0896 - acc: 0.9670 - val_loss: 0.3366 - val_acc: 0.9048\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0853 - acc: 0.9682 - val_loss: 0.3078 - val_acc: 0.9087\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0764 - acc: 0.9715 - val_loss: 0.3894 - val_acc: 0.8960\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0715 - acc: 0.9731 - val_loss: 0.3433 - val_acc: 0.9003\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0689 - acc: 0.9741 - val_loss: 0.3342 - val_acc: 0.9127\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.2574 - acc: 0.9225 - val_loss: 0.2631 - val_acc: 0.9067\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.1234 - acc: 0.9541 - val_loss: 0.2884 - val_acc: 0.9140\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0780 - acc: 0.9711 - val_loss: 0.3880 - val_acc: 0.8897\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.2341 - acc: 0.9163 - val_loss: 0.2925 - val_acc: 0.8932\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1447 - acc: 0.9454 - val_loss: 0.2613 - val_acc: 0.9142\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0961 - acc: 0.9638 - val_loss: 0.3075 - val_acc: 0.9105\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0788 - acc: 0.9706 - val_loss: 0.3175 - val_acc: 0.9100\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0778 - acc: 0.9720 - val_loss: 10.3703 - val_acc: 0.3145\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.1150 - acc: 0.9560 - val_loss: 0.3062 - val_acc: 0.9102\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0586 - acc: 0.9786 - val_loss: 0.4027 - val_acc: 0.9030\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0470 - acc: 0.9826 - val_loss: 0.3679 - val_acc: 0.9112\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0454 - acc: 0.9830 - val_loss: 0.3898 - val_acc: 0.9090\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0430 - acc: 0.9846 - val_loss: 0.3973 - val_acc: 0.9070\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0450 - acc: 0.9836 - val_loss: 0.3910 - val_acc: 0.9012\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0400 - acc: 0.9857 - val_loss: 0.4116 - val_acc: 0.9040\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 0.0403 - acc: 0.9846 - val_loss: 0.3609 - val_acc: 0.9162\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 104s 2ms/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.4334 - val_acc: 0.9025\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "H = model.fit(X_train, y_train,batch_size=128, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define y labels \n",
    "\n",
    "y_labels = ['t-shirts', 'trousers', 'pullovers', \n",
    "            'dresses', 'coats', 'sandals', 'shirts', \n",
    "            'sneakers', 'bags', 'ankle boots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "10000/10000 [==============================] - 4s 433us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    t-shirts       0.85      0.85      0.85      1000\n",
      "    trousers       0.99      0.98      0.99      1000\n",
      "   pullovers       0.79      0.90      0.84      1000\n",
      "     dresses       0.92      0.89      0.91      1000\n",
      "       coats       0.90      0.78      0.83      1000\n",
      "     sandals       0.98      0.98      0.98      1000\n",
      "      shirts       0.73      0.74      0.74      1000\n",
      "    sneakers       0.93      0.98      0.96      1000\n",
      "        bags       0.97      0.98      0.98      1000\n",
      " ankle boots       0.99      0.94      0.97      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.91      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "\n",
    "# Get probabilities\n",
    "predictions = model.predict(X_test, batch_size=128, verbose=1)\n",
    "\n",
    "# Get class labels for predictions\n",
    "pred_classes = predictions.argmax(axis=-1)\n",
    "\n",
    "# Get class labels for y_test\n",
    "y_test_classes = y_test.argmax(axis=-1)\n",
    "\n",
    "# show formatted classification report\n",
    "print(classification_report(y_test_classes, pred_classes,\n",
    "    target_names=y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC and AUC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), predictions.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(3), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Multiclass')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
